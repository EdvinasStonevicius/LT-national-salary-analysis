{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] ='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import = pd.read_csv('../Data/SQLout_employees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36785, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2018ft = data_import.query('arrangement == \"FT\" & year==2018', inplace=False )[['nace', \n",
    "                          'esize_class', 'gender', \n",
    "                          'age_class', 'lpk',  'education','experience', 'hourly_rate' ]]\n",
    "data=data2018ft.copy()\n",
    "data = data.rename(columns={'hourly_rate': 'target'})\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_iqr_upper(x, n=1.5):\n",
    "    \"\"\" check if x is outlier using IQR\"\"\"\n",
    "    iqr = x.quantile(0.75)-x.quantile(0.25)\n",
    "    upper_lim = x.quantile(0.75)+iqr*n\n",
    "    return x>=upper_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lpk2'] = data['lpk'] // 10\n",
    "data['outlier'] = data.groupby('lpk2')['target'].apply(outlier_iqr_upper, n=1.0)\n",
    "data=data.query('outlier==False')\n",
    "data = data.drop(columns=['outlier', 'lpk2'])\n",
    "data['lpk'] = data['lpk'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34259, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nace</th>\n",
       "      <th>esize_class</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_class</th>\n",
       "      <th>lpk</th>\n",
       "      <th>education</th>\n",
       "      <th>experience</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44952</th>\n",
       "      <td>C</td>\n",
       "      <td>1_49</td>\n",
       "      <td>M</td>\n",
       "      <td>50-59</td>\n",
       "      <td>722</td>\n",
       "      <td>G2</td>\n",
       "      <td>13</td>\n",
       "      <td>8.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44953</th>\n",
       "      <td>C</td>\n",
       "      <td>1_49</td>\n",
       "      <td>M</td>\n",
       "      <td>40-49</td>\n",
       "      <td>721</td>\n",
       "      <td>G2</td>\n",
       "      <td>13</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44954</th>\n",
       "      <td>C</td>\n",
       "      <td>1_49</td>\n",
       "      <td>M</td>\n",
       "      <td>50-59</td>\n",
       "      <td>722</td>\n",
       "      <td>G2</td>\n",
       "      <td>13</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44955</th>\n",
       "      <td>C</td>\n",
       "      <td>1_49</td>\n",
       "      <td>F</td>\n",
       "      <td>40-49</td>\n",
       "      <td>334</td>\n",
       "      <td>G2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44956</th>\n",
       "      <td>M</td>\n",
       "      <td>50_249</td>\n",
       "      <td>F</td>\n",
       "      <td>40-49</td>\n",
       "      <td>522</td>\n",
       "      <td>G2</td>\n",
       "      <td>18</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nace esize_class gender age_class  lpk education  experience  target\n",
       "44952    C        1_49      M     50-59  722        G2          13    8.13\n",
       "44953    C        1_49      M     40-49  721        G2          13    8.20\n",
       "44954    C        1_49      M     50-59  722        G2          13    8.20\n",
       "44955    C        1_49      F     40-49  334        G2           0    2.51\n",
       "44956    M      50_249      F     40-49  522        G2          18    2.19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.pop(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nace': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'nace')>,\n",
       " 'esize_class': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'esize_class')>,\n",
       " 'gender': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'gender')>,\n",
       " 'age_class': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'age_class')>,\n",
       " 'lpk': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'lpk')>,\n",
       " 'education': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'education')>,\n",
       " 'experience': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'experience')>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "for name, column in data.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name, input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = tf.keras.layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = tf.keras.layers.Normalization()\n",
    "norm.adapt(np.array(data[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = tf.keras.layers.StringLookup(vocabulary=np.unique(data[name]))\n",
    "  one_hot = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'normalization')>,\n",
       " <KerasTensor: shape=(None, 19) dtype=float32 (created by layer 'category_encoding')>,\n",
       " <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'category_encoding_1')>,\n",
       " <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'category_encoding_2')>,\n",
       " <KerasTensor: shape=(None, 6) dtype=float32 (created by layer 'category_encoding_3')>,\n",
       " <KerasTensor: shape=(None, 119) dtype=float32 (created by layer 'category_encoding_4')>,\n",
       " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'category_encoding_5')>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = tf.keras.layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "ltdu_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = ltdu_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltdu_features_dict = {name: np.array(value) \n",
    "                         for name, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 157), dtype=float32, numpy=\n",
       "array([[0.67940295, 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in ltdu_features_dict.items()}\n",
    "ltdu_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltdu_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()]),\n",
    "  return model\n",
    "\n",
    "ltdu_model = ltdu_model(ltdu_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1071/1071 [==============================] - 11s 9ms/step - loss: 5.0638 - root_mean_squared_error: 2.2503\n",
      "Epoch 2/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.8117 - root_mean_squared_error: 1.9524\n",
      "Epoch 3/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.6791 - root_mean_squared_error: 1.9181\n",
      "Epoch 4/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.6524 - root_mean_squared_error: 1.9111\n",
      "Epoch 5/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.6099 - root_mean_squared_error: 1.9000\n",
      "Epoch 6/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.5883 - root_mean_squared_error: 1.8943\n",
      "Epoch 7/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.5367 - root_mean_squared_error: 1.8806\n",
      "Epoch 8/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.5204 - root_mean_squared_error: 1.8763\n",
      "Epoch 9/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.5101 - root_mean_squared_error: 1.8735\n",
      "Epoch 10/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.4702 - root_mean_squared_error: 1.8628\n",
      "Epoch 11/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.4442 - root_mean_squared_error: 1.8559\n",
      "Epoch 12/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.4481 - root_mean_squared_error: 1.8569\n",
      "Epoch 13/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.4249 - root_mean_squared_error: 1.8506\n",
      "Epoch 14/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.4052 - root_mean_squared_error: 1.8453\n",
      "Epoch 15/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.3935 - root_mean_squared_error: 1.8422\n",
      "Epoch 16/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3825 - root_mean_squared_error: 1.8392\n",
      "Epoch 17/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.3967 - root_mean_squared_error: 1.8430\n",
      "Epoch 18/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3771 - root_mean_squared_error: 1.8377\n",
      "Epoch 19/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.3562 - root_mean_squared_error: 1.8320\n",
      "Epoch 20/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.3522 - root_mean_squared_error: 1.8309\n",
      "Epoch 21/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.3421 - root_mean_squared_error: 1.8281\n",
      "Epoch 22/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3344 - root_mean_squared_error: 1.8260\n",
      "Epoch 23/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3276 - root_mean_squared_error: 1.8242\n",
      "Epoch 24/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.3290 - root_mean_squared_error: 1.8245\n",
      "Epoch 25/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3037 - root_mean_squared_error: 1.8176\n",
      "Epoch 26/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3031 - root_mean_squared_error: 1.8174\n",
      "Epoch 27/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3237 - root_mean_squared_error: 1.8231\n",
      "Epoch 28/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3054 - root_mean_squared_error: 1.8181\n",
      "Epoch 29/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3107 - root_mean_squared_error: 1.8195\n",
      "Epoch 30/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.3071 - root_mean_squared_error: 1.8185\n",
      "Epoch 31/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.2985 - root_mean_squared_error: 1.8162\n",
      "Epoch 32/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.2873 - root_mean_squared_error: 1.8131\n",
      "Epoch 33/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.2782 - root_mean_squared_error: 1.8106\n",
      "Epoch 34/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2974 - root_mean_squared_error: 1.8159\n",
      "Epoch 35/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2891 - root_mean_squared_error: 1.8136\n",
      "Epoch 36/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2999 - root_mean_squared_error: 1.8166\n",
      "Epoch 37/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.2915 - root_mean_squared_error: 1.8142\n",
      "Epoch 38/50\n",
      "1071/1071 [==============================] - 9s 9ms/step - loss: 3.2886 - root_mean_squared_error: 1.8134\n",
      "Epoch 39/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2896 - root_mean_squared_error: 1.8137\n",
      "Epoch 40/50\n",
      "1071/1071 [==============================] - 11s 10ms/step - loss: 3.3032 - root_mean_squared_error: 1.8175\n",
      "Epoch 41/50\n",
      "1071/1071 [==============================] - 11s 10ms/step - loss: 3.2714 - root_mean_squared_error: 1.8087\n",
      "Epoch 42/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2842 - root_mean_squared_error: 1.8122\n",
      "Epoch 43/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2819 - root_mean_squared_error: 1.8116\n",
      "Epoch 44/50\n",
      "1071/1071 [==============================] - 11s 10ms/step - loss: 3.2905 - root_mean_squared_error: 1.8140\n",
      "Epoch 45/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2738 - root_mean_squared_error: 1.8094\n",
      "Epoch 46/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2809 - root_mean_squared_error: 1.8113\n",
      "Epoch 47/50\n",
      "1071/1071 [==============================] - 10s 9ms/step - loss: 3.2762 - root_mean_squared_error: 1.8100\n",
      "Epoch 48/50\n",
      "1071/1071 [==============================] - 10s 10ms/step - loss: 3.2731 - root_mean_squared_error: 1.8092\n",
      "Epoch 49/50\n",
      "1071/1071 [==============================] - 10s 10ms/step - loss: 3.2656 - root_mean_squared_error: 1.8071\n",
      "Epoch 50/50\n",
      "1071/1071 [==============================] - 10s 10ms/step - loss: 3.2928 - root_mean_squared_error: 1.8146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b781779a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltdu_model.fit(x=ltdu_features_dict, y=target, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fb52d76c6ca317d04f47a1b4ccd0834985762d1aaf348161a3099093323cd59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
